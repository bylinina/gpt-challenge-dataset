{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0e14e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNLI_DIR = \"./data/multinli_1.0\"\n",
    "\n",
    "import aiofiles\n",
    "import asyncio\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from async_openai import OpenAI, ChatResponse\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "OpenAI.configure(\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "    debug_enabled = False,\n",
    "    timeout = 60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7abdc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error in Loguru Handler #2 ---\n",
      "Record was: None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/erwin/.virtualenvs/thesis/lib/python3.10/site-packages/loguru/_handler.py\", line 291, in _queued_writer\n",
      "    message = queue.get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "TypeError: OpenAIError.__init__() missing 2 required positional arguments: 'response' and 'data'\n",
      "--- End of logging error ---\n"
     ]
    }
   ],
   "source": [
    "df_matched = pd.read_json(f'{MNLI_DIR}/multinli_1.0_dev_matched.jsonl', lines=True)\n",
    "# df_matched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b5fdbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['pir', 'sha', 'emb']\n",
    "N_SPLITS = len(splits)\n",
    "\n",
    "df_chunks = []\n",
    "df_splits_by_genre = [np.array_split(y, N_SPLITS) for x, y in df_matched.groupby(df_matched.genre)]\n",
    "\n",
    "for n_split in range(N_SPLITS):\n",
    "    df_chunks.append(pd.concat([df_genre_splits[n_split] for df_genre_splits in df_splits_by_genre]))\n",
    "    \n",
    "# for df_chunk in df_chunks:\n",
    "#     print([len(y) for x, y in df_chunk.groupby(df_chunk.genre)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a66c9140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in df_chunks[0].iterrows():\n",
    "#     print(row['sentence1'], '###', row['sentence2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b09de937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next message will contain a short text fragment. Rewrite the fragment using pirate speak, without changing the meaning of the text. Return two differing variations of the original text fragment. Format the output as following:\n",
      "\n",
      "1. {First variation here}\n",
      "2. {Second variation here}\n"
     ]
    }
   ],
   "source": [
    "def generate_prompt(style):\n",
    "    return f'The next message will contain a short text fragment. Rewrite the fragment using {style}, without changing the meaning of the text. Return two differing variations of the original text fragment. Format the output as following:\\n\\n1. {{First variation here}}\\n2. {{Second variation here}}'\n",
    "\n",
    "prompts = {\n",
    "    'pir': generate_prompt(\"pirate speak\"),\n",
    "    'sha': generate_prompt(\"Shakespearean English\"),\n",
    "    'emb': generate_prompt(\"embellished, flowery English\")\n",
    "}\n",
    "\n",
    "completion_data = []\n",
    "for count, split in enumerate(splits):\n",
    "    for index, row in df_chunks[count].iterrows():\n",
    "        completion_data.append(\n",
    "            {\n",
    "                \"split\": split,\n",
    "                \"prompt\": prompts[split],\n",
    "                \"pair_id\": row['pairID'],\n",
    "                \"text\": row['sentence1'],\n",
    "                \"sentence_no\": 1\n",
    "            }\n",
    "        )\n",
    "        completion_data.append(\n",
    "            {\n",
    "                \"split\": split,\n",
    "                \"prompt\": prompts[split],\n",
    "                \"pair_id\": row['pairID'],\n",
    "                \"text\": row['sentence2'],\n",
    "                \"sentence_no\": 2\n",
    "            }\n",
    "        )\n",
    "\n",
    "print(completion_data[0][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "506f545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "p = Path('./results')\n",
    "filenames = set('_'.join(pa.stem.split('_')[:2]) for pa in p.glob(\"*.json\"))\n",
    "\n",
    "filtered_completion_data = []\n",
    "for data_point in completion_data:\n",
    "    if f\"{data_point['pair_id']}_sen{data_point['sentence_no']}\" in filenames:\n",
    "        continue\n",
    "    filtered_completion_data.append(data_point)\n",
    "    \n",
    "print(len(filtered_completion_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94dbc9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "# def completions_with_backoff(**kwargs):\n",
    "#     return openai.ChatCompletion.create(**kwargs)\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": f\"The next message will contain a list of {N_LINES} text fragments. For each text fragment in the list, rewrite the fragment in pirate speak, whithout changing the meaning of the text. Create two variations for each list entry, and for each entry, format the results like this:\\n<This text fragment is variation 1> <This text fragment is variation 2>\"},\n",
    "#     {\"role\": \"user\", \"content\": '\\n'.join([f\"{row['sentence1']}\" for index, row in df_chunks[0].iterrows()][:N_LINES])}\n",
    "# ]\n",
    "\n",
    "# messages = []\n",
    "# for index, row in df_chunks[0].iterrows():\n",
    "#     messages.append(\n",
    "#         [\n",
    "#             {\"role\": \"user\", \"content\": f\"The next message will contain a short text fragment. Rewrite the fragment in pirate speak, without changing the meaning of the text. Return two differing variations of the original text fragment.\"},\n",
    "#             {\"role\": \"user\", \"content\": row['sentence1']}\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "# print(messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a69237e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO    \u001b[0m \u001b[32m2023-05-30 08:10:41.027\u001b[0m: \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m: \u001b[1mHTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async def chat_completion_to_file(split, prompt, pair_id, text, sentence_no):\n",
    "    result = await OpenAI.chat.async_create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "    )\n",
    "    async with aiofiles.open(f'results/{pair_id}_sen{sentence_no}_{split}.json', mode='w') as af:\n",
    "        result_dict = result.dict()\n",
    "        result_dict['created'] = result_dict['created'].isoformat()\n",
    "        await af.write(json.dumps(result_dict, indent=4, default=str))\n",
    "\n",
    "sem = asyncio.Semaphore(n := 40) # specify maximum concurrency\n",
    "\n",
    "async def task_wrapper(args):\n",
    "    try:\n",
    "        await chat_completion_to_file(**args)\n",
    "    finally:\n",
    "        sem.release()\n",
    "\n",
    "for args in filtered_completion_data: # may yield too many to list\n",
    "    await sem.acquire() \n",
    "    asyncio.create_task(task_wrapper(args))\n",
    "\n",
    "# wait for all tasks to complete\n",
    "for i in range(n):\n",
    "    await sem.acquire()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
